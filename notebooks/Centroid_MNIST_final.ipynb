{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "==>>> total training batch number: 235\n",
      "==>>> total testing batch number: 40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dataset\n",
    "from torch.utils.data import  DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageStat\n",
    "from visdom import Visdom\n",
    "\n",
    "# load MNIST dataset\n",
    "root = \"/home/robin/Thesis/Autoencoder/MNIST1_data\"\n",
    "if not(os.path.exists(root)):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "class MNIST1(dataset.MNIST):\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target,mean_pixel) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        \n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        \n",
    "        ##afine transform acording a randome offset\n",
    "        def affine_trans(img):\n",
    "            image = torch.squeeze(img,0)\n",
    "            rnumber = [random.uniform(-3,-3) for x in range(2)]\n",
    "            #returns a torch tensor of rnumber..\n",
    "            rnumber = torch.FloatTensor(rnumber)\n",
    "            x_offset,y_offset = rnumber \n",
    "            M = np.float32([[1,0,x_offset],[0,1,y_offset]])\n",
    "            rows,cols = rows,cols = image.shape[0:]\n",
    "            result = cv2.warpAffine(image.numpy(),M,(rows,cols))\n",
    "            result = torch.from_numpy(result).float()\n",
    "            return rnumber,result\n",
    "        \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            new_img = torch.squeeze(img,0)\n",
    "            rnumber,result = affine_trans(img)\n",
    "            centroid = list(ndimage.measurements.center_of_mass(new_img.numpy()))\n",
    "            centroid = torch.FloatTensor(centroid)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        values = {\"image\":img,\"target\":target,\n",
    "                 \"centroid\":centroid,\"randnum\":rnumber,\"warp_img\":result}\n",
    "        #return img,target,centroid_x,centroid_y,rnumber,result\n",
    "        return values\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "\n",
    "train_set = MNIST1(root=root, train=True, transform=trans, download=True)\n",
    "test_set = MNIST1(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                shuffle=True,pin_memory=False)\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                 batch_size=batch_size,\n",
    "                shuffle=True,pin_memory=False)\n",
    "#create a dataloader dictionary\n",
    "dataloaders = {\"train\":train_loader,\"val\":test_loader}\n",
    "\n",
    "print(len(dataloaders[\"train\"]))\n",
    "print ('==>>> total training batch number: {}'.format(len(train_loader)))\n",
    "print ('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder =  nn.Sequential(\n",
    "                        nn.Linear(28*28,256),\n",
    "                        nn.ReLU(True),\n",
    "                        nn.Linear(256,128),\n",
    "                        nn.ReLU(True),\n",
    "                        nn.Linear(128,64),nn.ReLU(True),\n",
    "                        nn.Linear(64,20)\n",
    "                        )\n",
    "        self.decoder =  nn.Sequential(\n",
    "                        nn.Linear(20,64),nn.ReLU(True),\n",
    "                        nn.Linear(64,128),nn.ReLU(True),\n",
    "                        nn.Linear(128,256),nn.ReLU(True),\n",
    "                        nn.Linear(256,28*28),nn.Tanh()\n",
    "                        )\n",
    "    def forward(self,x,offset):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = torch.add(offset,encoded)\n",
    "        decoded = self.decoder(decoded)\n",
    "        return encoded,decoded\n",
    "\n",
    "\n",
    "    \n",
    "class VisdomLinePlotter(object):\n",
    "    \"\"\"Plots to Visdom\"\"\"\n",
    "    def __init__(self, env_name='main'):\n",
    "        self.viz = Visdom()\n",
    "        self.env = env_name\n",
    "        self.plots = {}\n",
    "    def plot(self, var_name, split_name, title_name, x, y):\n",
    "        if var_name not in self.plots:\n",
    "            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n",
    "                legend=[split_name],\n",
    "                title=title_name,\n",
    "                xlabel='Epochs',\n",
    "                ylabel=var_name\n",
    "            ))\n",
    "        else:\n",
    "            self.viz.line(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name, update = 'append')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def train_val(model,criterion,optimizer,num_epochs):\n",
    "        best_loss = 1000.0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Epoch {}/{}\". format(epoch,num_epochs-1))\n",
    "            print(\"-\"*30)\n",
    "            since = time.time()\n",
    "            running_loss = 0.0\n",
    "            for phase in [\"train\",\"val\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                loss = 0.0\n",
    "                reconstruction_loss = 0.0 \n",
    "                centroid_loss = 0.0\n",
    "                \n",
    "                for index,sampled_batch in enumerate (dataloaders[phase]):\n",
    "                    image,warp_image =sampled_batch[\"image\"],sampled_batch[\"warp_img\"] \n",
    "                    inputs = image.view(image.size(0),-1).to(device)     #shape [batch_size*784]\n",
    "                    shifted_inputs = warp_image.view(warp_image.size(0),-1).to(device)   #shape [batch_size*784]\n",
    "                    offset = sampled_batch[\"randnum\"]   #shape [batch_size*2]\n",
    "                    #converted to the dimension of encoded o/p from model to get added.\n",
    "                    offset = F.pad(input=offset, pad=(18, 0, 0, 0), mode='constant', value=0)\n",
    "                    centroid = sampled_batch[\"centroid\"]   #shape [batch_size*2]\n",
    "                    ##since centre of mass (centroid return the y centroid first, we swap the\n",
    "                    #columns of centroid tensor..)\n",
    "                    centroid = torch.index_select(centroid, 1, torch.LongTensor([1,0]))\n",
    "                    \n",
    "                    #Forward\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        encode_out,output = model(inputs,offset.to(device))\n",
    "                        #make encode out to compute the loss between the centroid #shape [batch_size*2]\n",
    "                        centroid_out = encode_out[:,18:20]\n",
    "                        centroid_loss = criterion(centroid_out,centroid.to(device))\n",
    "                        #reconstruction loss between outputs and warped images\n",
    "                        reconstruction_loss = criterion(output,shifted_inputs.to(device))\n",
    "                        #Total loss ..\n",
    "                        loss = centroid_loss+reconstruction_loss\n",
    "                        ###backward\n",
    "                        if phase == \"train\":\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                \n",
    "                    #loss metrics\n",
    "                    running_loss+=loss.item()\n",
    "                    epoch_loss = loss.item()\n",
    "                #epoch_loss = running_loss\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    plotter.plot('Total loss', 'train', ' Loss', epoch, epoch_loss)\n",
    "                    plotter.plot(\"reconstruction_loss\", \"train\",\"recon_loss\",epoch,reconstruction_loss.item())\n",
    "                    plotter.plot(\"centroid_loss\", \"train\",\"centroid_loss\",epoch,centroid_loss.item())\n",
    "                else:\n",
    "                    plotter.plot('Total loss', 'validation', ' Loss', epoch, epoch_loss)\n",
    "                    plotter.plot(\"reconstruction_loss\", \"validation\",\"recon_loss\",epoch,reconstruction_loss.item())\n",
    "                    plotter.plot(\"centroid_loss\", \"validation\",\"centroid_loss\",epoch,centroid_loss.item())\n",
    "                        \n",
    "                print(\"{} --- Epoch {}, Epoch  loss : {:.4f} ,\".format(phase ,epoch,epoch_loss))\n",
    "                # saving the model\n",
    "                #if epoch %10 ==0:\n",
    "                if phase == \"val\" and epoch_loss<best_loss:\n",
    "                        best_loss = epoch_loss\n",
    "                        torch.save({ \"epoch\": epoch,\n",
    "                            \"model_state_dict\":model.state_dict(),\n",
    "                            \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "                            \"loss\":epoch_loss,\n",
    "                            },'/home/robin/Thesis/Autoencoder/logs/centroid_auto1/train_centroid1_epoch{}.pth'.format(epoch))\n",
    "                else:\n",
    "                        pass\n",
    "\n",
    "                time_elapsed = time.time()-since\n",
    "                print(\"Epoch complete in {:.0f}min - {:.0f}secs\".format(time_elapsed/60,time_elapsed%60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/connection.py\", line 159, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
      "    raise err\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/http/client.py\", line 1239, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/http/client.py\", line 1285, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/http/client.py\", line 1234, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/http/client.py\", line 964, in send\n",
      "    self.connect()\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/connection.py\", line 181, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fa17420f860>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/urllib3/util/retry.py\", line 398, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa17420f860>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/visdom/__init__.py\", line 548, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/requests/sessions.py\", line 581, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/robin/anaconda3/envs/torch/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa17420f860>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "ERROR:visdom:[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder().to(device)\n",
    "\n",
    "criterion= nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(),lr = 1.0,weight_decay=0.0)\n",
    "plotter = VisdomLinePlotter(env_name='Centroid Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_val(model,criterion,optimizer,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(inputs,output,n):\n",
    "    plt.figure(figsize= (18,4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2,n,i+1)\n",
    "        plt.imshow(inputs[i][0],cmap =\"gray\",interpolation ='none')\n",
    "        ax = plt.subplot(2,n ,i+1+n)\n",
    "        plt.imshow(output[i][0],cmap =\"gray\",interpolation ='none')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a8e992d5ac3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m     80\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#Evaluation \n",
    "logs_path = '/home/robin/Thesis/Autoencoder/logs/centroid_auto2/train_centroid2_epoch389.pth'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder().to(device)\n",
    "checkpoint = torch.load(logs_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.eval()\n",
    "\n",
    "for index,sampled_batch in enumerate (test_loader,0):\n",
    "    image,warp_image =sampled_batch[\"image\"],sampled_batch[\"warp_img\"] \n",
    "    inputs = image.view(image.size(0),-1).to(device)     #shape [batch_size*784]\n",
    "    shifted_inputs = warp_image.view(warp_image.size(0),-1).to(device)   #shape [batch_size*784]\n",
    "    offset = sampled_batch[\"randnum\"]   #shape [batch_size*2]\n",
    "    #converted to the dimension of encoded o/p from model to get added.\n",
    "    offset = F.pad(input=offset, pad=(18, 0, 0, 0), mode='constant', value=0)\n",
    "    centroid = sampled_batch[\"centroid\"]   #shape [batch_size*2]\n",
    "    ##since centre of mass (centroid return the y centroid first, we swap the\n",
    "    #columns of centroid tensor..)\n",
    "    centroid = torch.index_select(centroid, 1, torch.LongTensor([1,0]))\n",
    "\n",
    "    ##forward..\n",
    "    encode_out,output = model(inputs,offset.to(device))\n",
    "    \n",
    "    output = output.detach().cpu()\n",
    "    output = output.clamp(0,1)\n",
    "    output = output.view(output.size(0),1,28,28)\n",
    "   \n",
    "    warp_image = torch.unsqueeze(warp_image,1)\n",
    "    \n",
    "    visualize(warp_image,output,5)\n",
    "    #CHECK THE CENTROID BETWEEN WARP_IMAGE AND OUTPUT\n",
    "    print(\"originalimage centroid\",centroid[0])\n",
    "    centroid_output= list(ndimage.measurements.center_of_mass(output[0][0].numpy()))\n",
    "    centroid_image = list(ndimage.measurements.center_of_mass(warp_image[0][0].numpy()))\n",
    "    print(\"warp image centroid\",centroid_image)\n",
    "    print(\"centroid calculated from the reconstructed image\",centroid_output)\n",
    "    centroid_out = encode_out[:,18:20]\n",
    "    print(\"centroid values from model\",centroid_out[0].detach().cpu())\n",
    "    if index ==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
